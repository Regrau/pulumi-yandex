// *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.Yandex.Inputs
{

    public sealed class GetMdbClickhouseClusterUserSettingsArgs : global::Pulumi.InvokeArgs
    {
        /// <summary>
        /// Include CORS headers in HTTP responces.
        /// </summary>
        [Input("addHttpCorsHeader", required: true)]
        public bool AddHttpCorsHeader { get; set; }

        /// <summary>
        /// Allows or denies DDL queries.
        /// </summary>
        [Input("allowDdl", required: true)]
        public bool AllowDdl { get; set; }

        /// <summary>
        /// (Optional) Enables introspections functions for query profiling.
        /// </summary>
        [Input("allowIntrospectionFunctions", required: true)]
        public bool AllowIntrospectionFunctions { get; set; }

        /// <summary>
        /// (Optional) Allows specifying LowCardinality modifier for types of small fixed size (8 or less) in CREATE TABLE statements. Enabling this may increase merge times and memory consumption.
        /// </summary>
        [Input("allowSuspiciousLowCardinalityTypes", required: true)]
        public bool AllowSuspiciousLowCardinalityTypes { get; set; }

        /// <summary>
        /// (Optional) Enables asynchronous inserts. Disabled by default.
        /// </summary>
        [Input("asyncInsert", required: true)]
        public bool AsyncInsert { get; set; }

        /// <summary>
        /// (Optional) The maximum timeout in milliseconds since the first INSERT query before inserting collected data. If the parameter is set to 0, the timeout is disabled. Default value: 200.
        /// </summary>
        [Input("asyncInsertBusyTimeout", required: true)]
        public int AsyncInsertBusyTimeout { get; set; }

        /// <summary>
        /// (Optional) The maximum size of the unparsed data in bytes collected per query before being inserted. If the parameter is set to 0, asynchronous insertions are disabled. Default value: 100000.
        /// </summary>
        [Input("asyncInsertMaxDataSize", required: true)]
        public int AsyncInsertMaxDataSize { get; set; }

        /// <summary>
        /// (Optional) The maximum timeout in milliseconds since the last INSERT query before dumping collected data. If enabled, the settings prolongs the async_insert_busy_timeout with every INSERT query as long as async_insert_max_data_size is not exceeded.
        /// </summary>
        [Input("asyncInsertStaleTimeout", required: true)]
        public int AsyncInsertStaleTimeout { get; set; }

        /// <summary>
        /// (Optional) The maximum number of threads for background data parsing and insertion. If the parameter is set to 0, asynchronous insertions are disabled. Default value: 16.
        /// </summary>
        [Input("asyncInsertThreads", required: true)]
        public int AsyncInsertThreads { get; set; }

        /// <summary>
        /// (Optional) Cancels HTTP read-only queries (e.g. SELECT) when a client closes the connection without waiting for the response.
        /// Default value: false.
        /// </summary>
        [Input("cancelHttpReadonlyQueriesOnClientClose", required: true)]
        public bool CancelHttpReadonlyQueriesOnClientClose { get; set; }

        /// <summary>
        /// Enable compilation of queries.
        /// </summary>
        [Input("compile", required: true)]
        public bool Compile { get; set; }

        /// <summary>
        /// Turn on expression compilation.
        /// </summary>
        [Input("compileExpressions", required: true)]
        public bool CompileExpressions { get; set; }

        /// <summary>
        /// Connect timeout in milliseconds on the socket used for communicating with the client.
        /// </summary>
        [Input("connectTimeout", required: true)]
        public int ConnectTimeout { get; set; }

        /// <summary>
        /// (Optional) The timeout in milliseconds for connecting to a remote server for a Distributed table engine, if the ‘shard’ and ‘replica’ sections are used in the cluster definition. If unsuccessful, several attempts are made to connect to various replicas. Default value: 50.
        /// </summary>
        [Input("connectTimeoutWithFailover", required: true)]
        public int ConnectTimeoutWithFailover { get; set; }

        /// <summary>
        /// Specifies which of the uniq* functions should be used to perform the COUNT(DISTINCT …) construction.
        /// </summary>
        [Input("countDistinctImplementation", required: true)]
        public string CountDistinctImplementation { get; set; } = null!;

        /// <summary>
        /// Sets behaviour on overflow when using DISTINCT. Possible values:
        /// </summary>
        [Input("distinctOverflowMode", required: true)]
        public string DistinctOverflowMode { get; set; } = null!;

        /// <summary>
        /// Determine the behavior of distributed subqueries.
        /// </summary>
        [Input("distributedAggregationMemoryEfficient", required: true)]
        public bool DistributedAggregationMemoryEfficient { get; set; }

        /// <summary>
        /// Timeout for DDL queries, in milliseconds.
        /// </summary>
        [Input("distributedDdlTaskTimeout", required: true)]
        public int DistributedDdlTaskTimeout { get; set; }

        /// <summary>
        /// Changes the behaviour of distributed subqueries.
        /// </summary>
        [Input("distributedProductMode", required: true)]
        public string DistributedProductMode { get; set; } = null!;

        /// <summary>
        /// Allows to retunr empty result.
        /// </summary>
        [Input("emptyResultForAggregationByEmptySet", required: true)]
        public bool EmptyResultForAggregationByEmptySet { get; set; }

        /// <summary>
        /// Enables or disables data compression in the response to an HTTP request.
        /// </summary>
        [Input("enableHttpCompression", required: true)]
        public bool EnableHttpCompression { get; set; }

        /// <summary>
        /// Forces a query to an out-of-date replica if updated data is not available.
        /// </summary>
        [Input("fallbackToStaleReplicasForDistributedQueries", required: true)]
        public bool FallbackToStaleReplicasForDistributedQueries { get; set; }

        /// <summary>
        /// (Optional) Sets the data format of a nested columns.
        /// </summary>
        [Input("flattenNested", required: true)]
        public bool FlattenNested { get; set; }

        /// <summary>
        /// Disables query execution if the index can’t be used by date.
        /// </summary>
        [Input("forceIndexByDate", required: true)]
        public bool ForceIndexByDate { get; set; }

        /// <summary>
        /// Disables query execution if indexing by the primary key is not possible.
        /// </summary>
        [Input("forcePrimaryKey", required: true)]
        public bool ForcePrimaryKey { get; set; }

        /// <summary>
        /// Sets behaviour on overflow while GROUP BY operation. Possible values:
        /// </summary>
        [Input("groupByOverflowMode", required: true)]
        public string GroupByOverflowMode { get; set; } = null!;

        /// <summary>
        /// Sets the threshold of the number of keys, after that the two-level aggregation should be used.
        /// </summary>
        [Input("groupByTwoLevelThreshold", required: true)]
        public int GroupByTwoLevelThreshold { get; set; }

        /// <summary>
        /// Sets the threshold of the number of bytes, after that the two-level aggregation should be used.
        /// </summary>
        [Input("groupByTwoLevelThresholdBytes", required: true)]
        public int GroupByTwoLevelThresholdBytes { get; set; }

        /// <summary>
        /// Timeout for HTTP connection in milliseconds.
        /// </summary>
        [Input("httpConnectionTimeout", required: true)]
        public int HttpConnectionTimeout { get; set; }

        /// <summary>
        /// Sets minimal interval between notifications about request process in HTTP header X-ClickHouse-Progress.
        /// </summary>
        [Input("httpHeadersProgressInterval", required: true)]
        public int HttpHeadersProgressInterval { get; set; }

        /// <summary>
        /// Timeout for HTTP connection in milliseconds.
        /// </summary>
        [Input("httpReceiveTimeout", required: true)]
        public int HttpReceiveTimeout { get; set; }

        /// <summary>
        /// Timeout for HTTP connection in milliseconds.
        /// </summary>
        [Input("httpSendTimeout", required: true)]
        public int HttpSendTimeout { get; set; }

        /// <summary>
        /// When performing INSERT queries, replace omitted input column values with default values of the respective columns.
        /// </summary>
        [Input("inputFormatDefaultsForOmittedFields", required: true)]
        public bool InputFormatDefaultsForOmittedFields { get; set; }

        /// <summary>
        /// Enables or disables the full SQL parser if the fast stream parser can’t parse the data.
        /// </summary>
        [Input("inputFormatValuesInterpretExpressions", required: true)]
        public bool InputFormatValuesInterpretExpressions { get; set; }

        /// <summary>
        /// (Optional) Enables the insertion of default values instead of NULL into columns with not nullable data type. Default value: true.
        /// </summary>
        [Input("insertNullAsDefault", required: true)]
        public bool InsertNullAsDefault { get; set; }

        /// <summary>
        /// Enables the quorum writes.
        /// </summary>
        [Input("insertQuorum", required: true)]
        public int InsertQuorum { get; set; }

        /// <summary>
        /// Write to a quorum timeout in milliseconds.
        /// </summary>
        [Input("insertQuorumTimeout", required: true)]
        public int InsertQuorumTimeout { get; set; }

        /// <summary>
        /// Sets behaviour on overflow in JOIN. Possible values:
        /// </summary>
        [Input("joinOverflowMode", required: true)]
        public string JoinOverflowMode { get; set; } = null!;

        /// <summary>
        /// Sets the type of JOIN behaviour. When merging tables, empty cells may appear. ClickHouse fills them differently based on this setting.
        /// </summary>
        [Input("joinUseNulls", required: true)]
        public bool JoinUseNulls { get; set; }

        /// <summary>
        /// Require aliases for subselects and table functions in FROM that more than one table is present.
        /// </summary>
        [Input("joinedSubqueryRequiresAlias", required: true)]
        public bool JoinedSubqueryRequiresAlias { get; set; }

        /// <summary>
        /// Allows or restricts using the LowCardinality data type with the Native format.
        /// </summary>
        [Input("lowCardinalityAllowInNativeFormat", required: true)]
        public bool LowCardinalityAllowInNativeFormat { get; set; }

        /// <summary>
        /// Maximum abstract syntax tree depth.
        /// </summary>
        [Input("maxAstDepth", required: true)]
        public int MaxAstDepth { get; set; }

        /// <summary>
        /// Maximum abstract syntax tree elements.
        /// </summary>
        [Input("maxAstElements", required: true)]
        public int MaxAstElements { get; set; }

        /// <summary>
        /// A recommendation for what size of the block (in a count of rows) to load from tables.
        /// </summary>
        [Input("maxBlockSize", required: true)]
        public int MaxBlockSize { get; set; }

        /// <summary>
        /// Limit in bytes for using memoru for GROUP BY before using swap on disk.
        /// </summary>
        [Input("maxBytesBeforeExternalGroupBy", required: true)]
        public int MaxBytesBeforeExternalGroupBy { get; set; }

        /// <summary>
        /// This setting is equivalent of the max_bytes_before_external_group_by setting, except for it is for sort operation (ORDER BY), not aggregation.
        /// </summary>
        [Input("maxBytesBeforeExternalSort", required: true)]
        public int MaxBytesBeforeExternalSort { get; set; }

        /// <summary>
        /// Limits the maximum size of a hash table in bytes (uncompressed data) when using DISTINCT.
        /// </summary>
        [Input("maxBytesInDistinct", required: true)]
        public int MaxBytesInDistinct { get; set; }

        /// <summary>
        /// Limit on maximum size of the hash table for JOIN, in bytes.
        /// </summary>
        [Input("maxBytesInJoin", required: true)]
        public int MaxBytesInJoin { get; set; }

        /// <summary>
        /// Limit on the number of bytes in the set resulting from the execution of the IN section.
        /// </summary>
        [Input("maxBytesInSet", required: true)]
        public int MaxBytesInSet { get; set; }

        /// <summary>
        /// Limits the maximum number of bytes (uncompressed data) that can be read from a table when running a query.
        /// </summary>
        [Input("maxBytesToRead", required: true)]
        public int MaxBytesToRead { get; set; }

        /// <summary>
        /// Limits the maximum number of bytes (uncompressed data) that can be read from a table for sorting.
        /// </summary>
        [Input("maxBytesToSort", required: true)]
        public int MaxBytesToSort { get; set; }

        /// <summary>
        /// Limits the maximum number of bytes (uncompressed data) that can be passed to a remote server or saved in a temporary table when using GLOBAL IN.
        /// </summary>
        [Input("maxBytesToTransfer", required: true)]
        public int MaxBytesToTransfer { get; set; }

        /// <summary>
        /// Limits the maximum number of columns that can be read from a table in a single query.
        /// </summary>
        [Input("maxColumnsToRead", required: true)]
        public int MaxColumnsToRead { get; set; }

        /// <summary>
        /// (Optional) The maximum number of concurrent requests per user. Default value: 0 (no limit).
        /// </summary>
        [Input("maxConcurrentQueriesForUser", required: true)]
        public int MaxConcurrentQueriesForUser { get; set; }

        /// <summary>
        /// Limits the maximum query execution time in milliseconds.
        /// </summary>
        [Input("maxExecutionTime", required: true)]
        public int MaxExecutionTime { get; set; }

        /// <summary>
        /// Maximum abstract syntax tree depth after after expansion of aliases.
        /// </summary>
        [Input("maxExpandedAstElements", required: true)]
        public int MaxExpandedAstElements { get; set; }

        /// <summary>
        /// (Optional) Limits the maximum number of HTTP GET redirect hops for URL-engine tables.
        /// If the parameter is set to 0 (default), no hops is allowed.
        /// </summary>
        [Input("maxHttpGetRedirects", required: true)]
        public int MaxHttpGetRedirects { get; set; }

        /// <summary>
        /// The size of blocks (in a count of rows) to form for insertion into a table.
        /// </summary>
        [Input("maxInsertBlockSize", required: true)]
        public int MaxInsertBlockSize { get; set; }

        /// <summary>
        /// Limits the maximum memory usage (in bytes) for processing queries on a single server.
        /// </summary>
        [Input("maxMemoryUsage", required: true)]
        public int MaxMemoryUsage { get; set; }

        /// <summary>
        /// Limits the maximum memory usage (in bytes) for processing of user's queries on a single server.
        /// </summary>
        [Input("maxMemoryUsageForUser", required: true)]
        public int MaxMemoryUsageForUser { get; set; }

        /// <summary>
        /// Limits the speed of the data exchange over the network in bytes per second.
        /// </summary>
        [Input("maxNetworkBandwidth", required: true)]
        public int MaxNetworkBandwidth { get; set; }

        /// <summary>
        /// Limits the speed of the data exchange over the network in bytes per second.
        /// </summary>
        [Input("maxNetworkBandwidthForUser", required: true)]
        public int MaxNetworkBandwidthForUser { get; set; }

        /// <summary>
        /// The maximum part of a query that can be taken to RAM for parsing with the SQL parser.
        /// </summary>
        [Input("maxQuerySize", required: true)]
        public int MaxQuerySize { get; set; }

        /// <summary>
        /// Disables lagging replicas for distributed queries.
        /// </summary>
        [Input("maxReplicaDelayForDistributedQueries", required: true)]
        public int MaxReplicaDelayForDistributedQueries { get; set; }

        /// <summary>
        /// Limits the number of bytes in the result.
        /// </summary>
        [Input("maxResultBytes", required: true)]
        public int MaxResultBytes { get; set; }

        /// <summary>
        /// Limits the number of rows in the result.
        /// </summary>
        [Input("maxResultRows", required: true)]
        public int MaxResultRows { get; set; }

        /// <summary>
        /// Limits the maximum number of different rows when using DISTINCT.
        /// </summary>
        [Input("maxRowsInDistinct", required: true)]
        public int MaxRowsInDistinct { get; set; }

        /// <summary>
        /// Limit on maximum size of the hash table for JOIN, in rows.
        /// </summary>
        [Input("maxRowsInJoin", required: true)]
        public int MaxRowsInJoin { get; set; }

        /// <summary>
        /// Limit on the number of rows in the set resulting from the execution of the IN section.
        /// </summary>
        [Input("maxRowsInSet", required: true)]
        public int MaxRowsInSet { get; set; }

        /// <summary>
        /// Limits the maximum number of unique keys received from aggregation function.
        /// </summary>
        [Input("maxRowsToGroupBy", required: true)]
        public int MaxRowsToGroupBy { get; set; }

        /// <summary>
        /// Limits the maximum number of rows that can be read from a table when running a query.
        /// </summary>
        [Input("maxRowsToRead", required: true)]
        public int MaxRowsToRead { get; set; }

        /// <summary>
        /// Limits the maximum number of rows that can be read from a table for sorting.
        /// </summary>
        [Input("maxRowsToSort", required: true)]
        public int MaxRowsToSort { get; set; }

        /// <summary>
        /// Limits the maximum number of rows that can be passed to a remote server or saved in a temporary table when using GLOBAL IN.
        /// </summary>
        [Input("maxRowsToTransfer", required: true)]
        public int MaxRowsToTransfer { get; set; }

        /// <summary>
        /// Limits the maximum number of temporary columns that must be kept in RAM at the same time when running a query, including constant columns.
        /// </summary>
        [Input("maxTemporaryColumns", required: true)]
        public int MaxTemporaryColumns { get; set; }

        /// <summary>
        /// Limits the maximum number of temporary columns that must be kept in RAM at the same time when running a query, excluding constant columns.
        /// </summary>
        [Input("maxTemporaryNonConstColumns", required: true)]
        public int MaxTemporaryNonConstColumns { get; set; }

        /// <summary>
        /// The maximum number of query processing threads, excluding threads for retrieving data from remote servers.
        /// </summary>
        [Input("maxThreads", required: true)]
        public int MaxThreads { get; set; }

        /// <summary>
        /// (Optional) Collect random allocations and deallocations and write them into system.trace_log with 'MemorySample' trace_type. The probability is for every alloc/free regardless to the size of the allocation. Possible values: from 0 to 1. Default: 0.
        /// </summary>
        [Input("memoryProfilerSampleProbability", required: true)]
        public double MemoryProfilerSampleProbability { get; set; }

        /// <summary>
        /// (Optional) Memory profiler step (in bytes).  If the next query step requires more memory than this parameter specifies, the memory profiler collects the allocating stack trace. Values lower than a few megabytes slow down query processing. Default value: 4194304 (4 MB). Zero means disabled memory profiler.
        /// </summary>
        [Input("memoryProfilerStep", required: true)]
        public int MemoryProfilerStep { get; set; }

        /// <summary>
        /// If ClickHouse should read more than merge_tree_max_bytes_to_use_cache bytes in one query, it doesn’t use the cache of uncompressed blocks.
        /// </summary>
        [Input("mergeTreeMaxBytesToUseCache", required: true)]
        public int MergeTreeMaxBytesToUseCache { get; set; }

        /// <summary>
        /// If ClickHouse should read more than merge_tree_max_rows_to_use_cache rows in one query, it doesn’t use the cache of uncompressed blocks.
        /// </summary>
        [Input("mergeTreeMaxRowsToUseCache", required: true)]
        public int MergeTreeMaxRowsToUseCache { get; set; }

        /// <summary>
        /// If the number of bytes to read from one file of a MergeTree-engine table exceeds merge_tree_min_bytes_for_concurrent_read, then ClickHouse tries to concurrently read from this file in several threads.
        /// </summary>
        [Input("mergeTreeMinBytesForConcurrentRead", required: true)]
        public int MergeTreeMinBytesForConcurrentRead { get; set; }

        /// <summary>
        /// If the number of rows to be read from a file of a MergeTree table exceeds merge_tree_min_rows_for_concurrent_read then ClickHouse tries to perform a concurrent reading from this file on several threads.
        /// </summary>
        [Input("mergeTreeMinRowsForConcurrentRead", required: true)]
        public int MergeTreeMinRowsForConcurrentRead { get; set; }

        /// <summary>
        /// The minimum data volume required for using direct I/O access to the storage disk.
        /// </summary>
        [Input("minBytesToUseDirectIo", required: true)]
        public int MinBytesToUseDirectIo { get; set; }

        /// <summary>
        /// How many times to potentially use a compiled chunk of code before running compilation.
        /// </summary>
        [Input("minCountToCompile", required: true)]
        public int MinCountToCompile { get; set; }

        /// <summary>
        /// A query waits for expression compilation process to complete prior to continuing execution.
        /// </summary>
        [Input("minCountToCompileExpression", required: true)]
        public int MinCountToCompileExpression { get; set; }

        /// <summary>
        /// Minimal execution speed in rows per second.
        /// </summary>
        [Input("minExecutionSpeed", required: true)]
        public int MinExecutionSpeed { get; set; }

        /// <summary>
        /// Minimal execution speed in bytes per second.
        /// </summary>
        [Input("minExecutionSpeedBytes", required: true)]
        public int MinExecutionSpeedBytes { get; set; }

        /// <summary>
        /// Sets the minimum number of bytes in the block which can be inserted into a table by an INSERT query.
        /// </summary>
        [Input("minInsertBlockSizeBytes", required: true)]
        public int MinInsertBlockSizeBytes { get; set; }

        /// <summary>
        /// Sets the minimum number of rows in the block which can be inserted into a table by an INSERT query.
        /// </summary>
        [Input("minInsertBlockSizeRows", required: true)]
        public int MinInsertBlockSizeRows { get; set; }

        /// <summary>
        /// If the value is true, integers appear in quotes when using JSON* Int64 and UInt64 formats (for compatibility with most JavaScript implementations); otherwise, integers are output without the quotes.
        /// </summary>
        [Input("outputFormatJsonQuote64bitIntegers", required: true)]
        public bool OutputFormatJsonQuote64bitIntegers { get; set; }

        /// <summary>
        /// Enables +nan, -nan, +inf, -inf outputs in JSON output format.
        /// </summary>
        [Input("outputFormatJsonQuoteDenormals", required: true)]
        public bool OutputFormatJsonQuoteDenormals { get; set; }

        /// <summary>
        /// Query priority.
        /// </summary>
        [Input("priority", required: true)]
        public int Priority { get; set; }

        /// <summary>
        /// Quota accounting mode.
        /// </summary>
        [Input("quotaMode", required: true)]
        public string QuotaMode { get; set; } = null!;

        /// <summary>
        /// Sets behaviour on overflow while read. Possible values:
        /// </summary>
        [Input("readOverflowMode", required: true)]
        public string ReadOverflowMode { get; set; } = null!;

        /// <summary>
        /// Restricts permissions for reading data, write data and change settings queries.
        /// </summary>
        [Input("readonly", required: true)]
        public int Readonly { get; set; }

        /// <summary>
        /// Receive timeout in milliseconds on the socket used for communicating with the client.
        /// </summary>
        [Input("receiveTimeout", required: true)]
        public int ReceiveTimeout { get; set; }

        /// <summary>
        /// For ALTER ... ATTACH|DETACH|DROP queries, you can use the replication_alter_partitions_sync setting to set up waiting.
        /// </summary>
        [Input("replicationAlterPartitionsSync", required: true)]
        public int ReplicationAlterPartitionsSync { get; set; }

        /// <summary>
        /// Sets behaviour on overflow in result. Possible values:
        /// </summary>
        [Input("resultOverflowMode", required: true)]
        public string ResultOverflowMode { get; set; } = null!;

        /// <summary>
        /// Enables or disables sequential consistency for SELECT queries.
        /// </summary>
        [Input("selectSequentialConsistency", required: true)]
        public bool SelectSequentialConsistency { get; set; }

        /// <summary>
        /// Enables or disables X-ClickHouse-Progress HTTP response headers in clickhouse-server responses.
        /// </summary>
        [Input("sendProgressInHttpHeaders", required: true)]
        public bool SendProgressInHttpHeaders { get; set; }

        /// <summary>
        /// Send timeout in milliseconds on the socket used for communicating with the client.
        /// </summary>
        [Input("sendTimeout", required: true)]
        public int SendTimeout { get; set; }

        /// <summary>
        /// Sets behaviour on overflow in the set resulting. Possible values:
        /// </summary>
        [Input("setOverflowMode", required: true)]
        public string SetOverflowMode { get; set; } = null!;

        /// <summary>
        /// Enables or disables silently skipping of unavailable shards.
        /// </summary>
        [Input("skipUnavailableShards", required: true)]
        public bool SkipUnavailableShards { get; set; }

        /// <summary>
        /// Sets behaviour on overflow while sort. Possible values:
        /// </summary>
        [Input("sortOverflowMode", required: true)]
        public string SortOverflowMode { get; set; } = null!;

        /// <summary>
        /// (Optional) Timeout (in seconds) between checks of execution speed. It is checked that execution speed is not less that specified in min_execution_speed parameter.
        /// Must be at least 1000.
        /// </summary>
        [Input("timeoutBeforeCheckingExecutionSpeed", required: true)]
        public int TimeoutBeforeCheckingExecutionSpeed { get; set; }

        /// <summary>
        /// Sets behaviour on overflow. Possible values:
        /// </summary>
        [Input("timeoutOverflowMode", required: true)]
        public string TimeoutOverflowMode { get; set; } = null!;

        /// <summary>
        /// Sets behaviour on overflow. Possible values:
        /// </summary>
        [Input("transferOverflowMode", required: true)]
        public string TransferOverflowMode { get; set; } = null!;

        /// <summary>
        /// Enables equality of NULL values for IN operator.
        /// </summary>
        [Input("transformNullIn", required: true)]
        public bool TransformNullIn { get; set; }

        /// <summary>
        /// Whether to use a cache of uncompressed blocks.
        /// </summary>
        [Input("useUncompressedCache", required: true)]
        public bool UseUncompressedCache { get; set; }

        /// <summary>
        /// (Optional) Enables waiting for processing of asynchronous insertion. If enabled, server returns OK only after the data is inserted.
        /// </summary>
        [Input("waitForAsyncInsert", required: true)]
        public bool WaitForAsyncInsert { get; set; }

        /// <summary>
        /// (Optional) The timeout (in seconds) for waiting for processing of asynchronous insertion. Value must be at least 1000 (1 second).
        /// </summary>
        [Input("waitForAsyncInsertTimeout", required: true)]
        public int WaitForAsyncInsertTimeout { get; set; }

        public GetMdbClickhouseClusterUserSettingsArgs()
        {
        }
        public static new GetMdbClickhouseClusterUserSettingsArgs Empty => new GetMdbClickhouseClusterUserSettingsArgs();
    }
}
